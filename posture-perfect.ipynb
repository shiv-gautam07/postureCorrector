{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T15:10:40.269989Z",
     "start_time": "2024-05-12T15:10:40.266589Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "import math as m\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T15:10:40.563809Z",
     "start_time": "2024-05-12T15:10:40.560303Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate distance\n",
    "def findDistance(x1, y1, x2, y2):\n",
    "    dist = m.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T15:10:41.354226Z",
     "start_time": "2024-05-12T15:10:41.350760Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate angle.\n",
    "def findAngle(x1, y1, x2, y2):\n",
    "    theta = m.acos((y2 - y1) * (-y1) / (m.sqrt(\n",
    "        (x2 - x1) ** 2 + (y2 - y1) ** 2) * y1))\n",
    "    degree = int(180 / m.pi) * theta\n",
    "    return degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T15:11:02.562885Z",
     "start_time": "2024-05-12T15:10:41.879372Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Harshit Singla\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null.Frames\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Function to send alert. Use this function to send alert when bad posture detected.\n",
    "Feel free to get creative and customize as per your convenience.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def sendWarning(x):\n",
    "     pass\n",
    "\n",
    "\n",
    "# =============================CONSTANTS and INITIALIZATIONS=====================================#\n",
    "# Initilize frame counters.\n",
    "good_frames = 0\n",
    "bad_frames = 0\n",
    "\n",
    "# Font type.\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "# Colors.\n",
    "blue = (255, 127, 0)\n",
    "red = (50, 50, 255)\n",
    "green = (127, 255, 0)\n",
    "dark_blue = (127, 20, 0)\n",
    "light_green = (127, 233, 100)\n",
    "yellow = (0, 255, 255)\n",
    "pink = (255, 0, 255)\n",
    "\n",
    "# Initialize mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose()\n",
    "# ===============================================================================================#\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # For webcam input replace file name with 0.\n",
    "    file_name = 'input.mp4'\n",
    "    cap = cv2.VideoCapture(file_name)\n",
    "\n",
    "    # Meta.\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_size = (width, height)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "    # Video writer.\n",
    "    video_output = cv2.VideoWriter('output.mp4', fourcc, fps, frame_size)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        # Capture frames.\n",
    "        success, image = cap.read()\n",
    "        if not success:\n",
    "            print(\"Null.Frames\")\n",
    "            break\n",
    "        # Get fps.\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "        # Get height and width.\n",
    "        h, w = image.shape[:2]\n",
    "\n",
    "        # Convert the BGR image to RGB.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Process the image.\n",
    "        keypoints = pose.process(image)\n",
    "\n",
    "        # Convert the image back to BGR.\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Use lm and lmPose as representative of the following methods.\n",
    "        lm = keypoints.pose_landmarks\n",
    "        lmPose = mp_pose.PoseLandmark\n",
    "\n",
    "        # Acquire the landmark coordinates.\n",
    "        # Once aligned properly, left or right should not be a concern.      \n",
    "        # Left shoulder.\n",
    "        l_shldr_x = int(lm.landmark[lmPose.LEFT_SHOULDER].x * w)\n",
    "        l_shldr_y = int(lm.landmark[lmPose.LEFT_SHOULDER].y * h)\n",
    "        # Right shoulder\n",
    "        r_shldr_x = int(lm.landmark[lmPose.RIGHT_SHOULDER].x * w)\n",
    "        r_shldr_y = int(lm.landmark[lmPose.RIGHT_SHOULDER].y * h)\n",
    "        # Left ear.\n",
    "        l_ear_x = int(lm.landmark[lmPose.LEFT_EAR].x * w)\n",
    "        l_ear_y = int(lm.landmark[lmPose.LEFT_EAR].y * h)\n",
    "        # Left hip.\n",
    "        l_hip_x = int(lm.landmark[lmPose.LEFT_HIP].x * w)\n",
    "        l_hip_y = int(lm.landmark[lmPose.LEFT_HIP].y * h)\n",
    "\n",
    "        # Calculate distance between left shoulder and right shoulder points.\n",
    "        offset = findDistance(l_shldr_x, l_shldr_y, r_shldr_x, r_shldr_y)\n",
    "\n",
    "        # Assist to align the camera to point at the side view of the person.\n",
    "        if offset < 100:\n",
    "            cv2.putText(image, str(int(offset)) + ' Aligned', (w - 150, 30), font, 0.9, green, 2)\n",
    "        else:\n",
    "            cv2.putText(image, str(int(offset)) + ' Not Aligned', (w - 150, 30), font, 0.9, red, 2)\n",
    "\n",
    "        # Calculate angles.\n",
    "        neck_inclination = findAngle(l_shldr_x, l_shldr_y, l_ear_x, l_ear_y)\n",
    "        torso_inclination = findAngle(l_hip_x, l_hip_y, l_shldr_x, l_shldr_y)\n",
    "\n",
    "        # Draw landmarks.\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y), 7, yellow, -1)\n",
    "        cv2.circle(image, (l_ear_x, l_ear_y), 7, yellow, -1)\n",
    "\n",
    "        # Let's take y - coordinate of P3 100px above x1,  for display elegance.\n",
    "        # Although we are taking y = 0 while calculating angle between P1,P2,P3.\n",
    "        cv2.circle(image, (l_shldr_x, l_shldr_y - 100), 7, yellow, -1)\n",
    "        cv2.circle(image, (r_shldr_x, r_shldr_y), 7, pink, -1)\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y), 7, yellow, -1)\n",
    "\n",
    "        # Similarly, here we are taking y - coordinate 100px above x1. Note that\n",
    "        # you can take any value for y, not necessarily 100 or 200 pixels.\n",
    "        cv2.circle(image, (l_hip_x, l_hip_y - 100), 7, yellow, -1)\n",
    "\n",
    "        # Put text, Posture and angle inclination.\n",
    "        # Text string for display.\n",
    "        angle_text_string = 'Neck : ' + str(int(neck_inclination)) + '  Torso : ' + str(int(torso_inclination))\n",
    "\n",
    "        # Determine whether good posture or bad posture.\n",
    "        # The threshold angles have been set based on intuition.\n",
    "        if neck_inclination < 40 and torso_inclination < 10:\n",
    "            bad_frames = 0\n",
    "            good_frames += 1\n",
    "            \n",
    "            cv2.putText(image, angle_text_string, (10, 30), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(neck_inclination)), (l_shldr_x + 10, l_shldr_y), font, 0.9, light_green, 2)\n",
    "            cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 0.9, light_green, 2)\n",
    "\n",
    "            # Join landmarks.\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), green, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), green, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), green, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), green, 4)\n",
    "\n",
    "        else:\n",
    "            good_frames = 0\n",
    "            bad_frames += 1\n",
    "\n",
    "            cv2.putText(image, angle_text_string, (10, 30), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(neck_inclination)), (l_shldr_x + 10, l_shldr_y), font, 0.9, red, 2)\n",
    "            cv2.putText(image, str(int(torso_inclination)), (l_hip_x + 10, l_hip_y), font, 0.9, red, 2)\n",
    "\n",
    "            # Join landmarks.\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_ear_x, l_ear_y), red, 4)\n",
    "            cv2.line(image, (l_shldr_x, l_shldr_y), (l_shldr_x, l_shldr_y - 100), red, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_shldr_x, l_shldr_y), red, 4)\n",
    "            cv2.line(image, (l_hip_x, l_hip_y), (l_hip_x, l_hip_y - 100), red, 4)\n",
    "\n",
    "        # Calculate the time of remaining in a particular posture.\n",
    "        good_time = (1 / fps) * good_frames\n",
    "        bad_time =  (1 / fps) * bad_frames\n",
    "\n",
    "        # Pose time.\n",
    "        if good_time > 0:\n",
    "            time_string_good = 'Good Posture Time : ' + str(round(good_time, 1)) + 's'\n",
    "            cv2.putText(image, time_string_good, (10, h - 20), font, 0.9, green, 2)\n",
    "        else:\n",
    "            time_string_bad = 'Bad Posture Time : ' + str(round(bad_time, 1)) + 's'\n",
    "            cv2.putText(image, time_string_bad, (10, h - 20), font, 0.9, red, 2)\n",
    "\n",
    "        # If you stay in bad posture for more than 3 minutes (180s) send an alert.\n",
    "        if bad_time > 180:\n",
    "            sendWarning()\n",
    "        # Write frames.\n",
    "        video_output.write(image)\n",
    "\n",
    "        # Display.\n",
    "        cv2.imshow('MediaPipe Pose', image)\n",
    "        if cv2.waitKey(5) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
